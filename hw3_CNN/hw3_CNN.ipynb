{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKjr6A5UJ34P"
   },
   "source": [
    "\n",
    "# hw3_CNN\n",
    "\n",
    "题目：食物的分类\n",
    "\n",
    "kaggle link:https://www.kaggle.com/c/ml2020spring-hw3 （数据集大小1.1GB）\n",
    "\n",
    "Strong Baseline: 0.79928\n",
    "\n",
    "Simple Baseline: 0.70788\n",
    "\n",
    "第一次提交：0.60251(**<font color='red'>未达标</font>**)\n",
    "\n",
    "第一次提交：0.79378(**<font color='grenn'>勉强算达标strong baseline吧Q_Q</font>**)\n",
    "\n",
    "**关键词：** CNN;Classification;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YxjBaB7-J34W"
   },
   "source": [
    "### PyTorch小知识\n",
    "\n",
    "`torch.utils.data.Dataset`\n",
    "\n",
    "Dataset分为两种：1. map-style dataset 2. iterable-style dataset\n",
    "\n",
    "本程序中使用的是map-style dataset\n",
    "\n",
    "映射形式的数据集的类需要实现\\_\\_getitem__() 和 \\_\\_len__()函数来通过index进行数据访问和查看数据集的长度。\n",
    "\n",
    "For example, such a dataset, when accessed with dataset[idx], could read the idx-th image and its corresponding label from a folder on the disk.\n",
    "\n",
    "\n",
    "`torch.utils.data.DataLoader` 是pytorch数据加载中最实用的包，能够以迭代的形式加载数据集。\n",
    "\n",
    "其可以：\n",
    "\n",
    "* 映射以及迭代的方式加载数据集（map-style and iterable-style）\n",
    "* 自定义数据加载方式\n",
    "* 自动分批（batch）\n",
    "* 单线程或者多线程加载数据\n",
    "* …………\n",
    "\n",
    "\n",
    "`torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride = 1, padding = 0, dilation = 1, groups = 1)`\n",
    "\n",
    "* `in_channels`: 输入通道。 什么是通道：https://blog.csdn.net/sscc_learning/article/details/79814146\n",
    "* `out_channels`: 输出通道。一般取决于卷积核的数量。\n",
    "* `kernel_size`: 卷积核的大小，当卷积是方形的时候为整数边长，不是方形要输入元组表示高和宽。\n",
    "* `stride`: 卷积核移动的步长\n",
    "* `padding`: 对原图像卷积的填充。\n",
    "* `dilation`: (先不管，在这里没啥用\n",
    "\n",
    "### GPU内存不足\n",
    "\n",
    "  使用了Google的colab，也可以每个月花$9.99购买Google的colab pro https://colab.research.google.com/signup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lvg0PjsBJ34X",
    "outputId": "d6bd3e41-0934-42b2-a611-62d1612ef848",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!gdown --id '19CzXudqN58R3D-1G8KeFWk8UDQwlb8is' --output food-11.zip # 下載資料集\n",
    "!unzip food-11.zip # 解壓縮"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_suhzipKK6n5"
   },
   "source": [
    "这里使用谷歌的colab，自己的显卡不太行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fDL4-DZGLAR2"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import torch as tc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "from torch.utils.data import dataset, dataloader  # 用于包装data，方便training和testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-A32GYKFLOk1"
   },
   "source": [
    "引用包文件，这里使用到了dataset和dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hwQtSeL9J34X",
    "outputId": "6c7c4815-a591-49ff-9a7b-e1f14e8579b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read train file over. Time 60.0 s\n",
      "Train len: 9866\n"
     ]
    }
   ],
   "source": [
    "# read pics\n",
    "\n",
    "def read_file(path, label):\n",
    "    img_dir = sorted(os.listdir(path))\n",
    "    LEN = len(img_dir) #len(img_dir)\n",
    "    x = np.zeros((LEN, 128, 128, 3), 'uint8')   # 图片必须是uint8\n",
    "    y = np.zeros((LEN, ), 'uint8')\n",
    "    for i, file in enumerate(img_dir):\n",
    "        if i >= LEN:\n",
    "            break\n",
    "        img = cv2.imread(f'{path}/{file}')\n",
    "        x[i, :, :, :] = cv2.resize(img, (128, 128))  # 调整图片大小\n",
    "        if label:\n",
    "            y[i] = int(file.split('_')[0])\n",
    "    if label:\n",
    "        return x, y\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "\n",
    "s_time = time.time()\n",
    "dir_path = './food-11'\n",
    "train_x, train_y = read_file(os.path.join(dir_path, \"training\"), True)\n",
    "valid_x, valid_y = read_file(os.path.join(dir_path, \"validation\"), True)\n",
    "# test_x = read_file('food/testing',False)\n",
    "print(f'read train file over. Time {round(time.time() - s_time, 2)} s')\n",
    "print(f\"Train len: {len(train_x)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fT8ogLmHK55S"
   },
   "source": [
    "读取图片文件。\n",
    "* 直接创建一个四维数组，用于承载图片，第一位表示图片的数量。记住：因为是图片，因此其np的类型必须是`uint8`的byte类型，否则会报错。\n",
    "* `cv2.resize()`函数不是截取对应的图片范围，而是将整个图片放缩到对应的像素（会变形）\n",
    "* 对于不同的系统路径处理使用`os.path.join(dir_path, filename)`处理更好\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1X5NMK-DKwnd"
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([  # 一系列处理图片使用Compose\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(),  # 随机水平旋转\n",
    "    transforms.RandomRotation(15),  # 随机旋转\n",
    "    transforms.ToTensor()  # 图片转为tensor\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awT6-w9rNd84"
   },
   "source": [
    "定义transforms, 对图片进行一系列处理，先进行`transforms.ToPILImage()`,最后`transforms.ToTensor()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "__kfgRpBKz_C"
   },
   "outputs": [],
   "source": [
    "class ImgDataset(dataset.Dataset):  # 继承父类dataset\n",
    "    def __init__(self, x, y=None, transform=None):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        if y is not None:\n",
    "            self.y = tc.LongTensor(y)  # y 应该为Long Tensor\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):  # 实现函数__len__\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, index):  # 实现函数__getitem__\n",
    "        X = self.x[index]\n",
    "        if self.transform is not None:\n",
    "            X = self.transform(X)\n",
    "        if self.y is not None:\n",
    "            return X, self.y[index]\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YngMY34HYZOe"
   },
   "source": [
    "对于dataset类，需要引入`torch.utils.data`，进行数据处理，dataset和dataloader可以快速方便的对数据集进行数据的迭代选择，方便数据处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vsIgmHjmJ34Y"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_set = ImgDataset(train_x, train_y, train_transform) # 顺便进行数据的transform，对于数据进行预处理\n",
    "valid_set = ImgDataset(valid_x, valid_y, test_transform)\n",
    "train_loader = dataloader.DataLoader(train_set, batch_size, True) # 设置batch_size对数据进行小批量训练。并且打乱顺序。\n",
    "valid_loader = dataloader.DataLoader(valid_set, batch_size, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iEhKmaLjYzgS"
   },
   "source": [
    "设置batch_size和进行data加载器。对于训练集的dataloader要进行打乱顺序进行数据增强，设置为`True`。当然验证集就没有要求了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "leVEe8_sJ34Y"
   },
   "outputs": [],
   "source": [
    "# 搭建模型\n",
    "\n",
    "class Classifier(nn.Module):    # 继承父类nn.Module\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n",
    "        # 原图输入维度 (128, 128, 3)\n",
    "        self.cnn = nn.Sequential(\n",
    "            # 输入为彩色图片，输出通道64 ，3X3的卷积核，1步长， 填充长度为1=>为了凑128，不然126不容易解决\n",
    "            nn.Conv2d(3, 64, 3, 1, 1),  # (128, 128, 64)\n",
    "            nn.BatchNorm2d(64), # norm2d的输入为特征数量，并进行标准化，这里可以设置momentum和eps\n",
    "            nn.ReLU(),  # 进行ReLU函数转换\n",
    "            nn.MaxPool2d(2, 2, 0),  # (64, 64, 64)\n",
    "\n",
    "            # 上一个conv + maxpool的输出为这次的输入\n",
    "            nn.Conv2d(64, 128, 3, 1, 1),  # (64, 64, 128)\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),  # (32, 32, 128)\n",
    "\n",
    "            nn.Conv2d(128, 256, 3, 1, 1),  # (32, 32, 256)\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),  # (16, 16, 256)\n",
    "\n",
    "            nn.Conv2d(256, 512, 3, 1, 1),  # (16, 16, 512)\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),  # (8, 8, 512)\n",
    "\n",
    "            nn.Conv2d(512, 512, 3, 1, 1),  # (8, 8, 512)\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),  # (4, 4, 512)\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512 * 4 * 4, 1024),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 11)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.cnn(x) # 进行CNN转换\n",
    "        out = out.view(out.size()[0], -1)   # 总感觉这句话没什么用\n",
    "        return self.fc(out) # 输入网络，有四层网络：输入层，隐藏层1，隐藏层2，输出层。最后输出11维度的向量（有11种类别的食品）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jM_q74a4Zh7N"
   },
   "source": [
    "对于分类器一定要继承`nn.Module`。这里进行五步：卷积->标准化->输出->池化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OixsnySqNybP",
    "outputId": "bf653ec4-cbe8-4334-e738-9edfc9df9807"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/30]: Time: 23.84s, Train acc/loss:20.616300000000003% / 1.7656%, Validation acc/loss:25.860100000000003% / 1.6306999999999998%\n",
      "[2/30]: Time: 24.4s, Train acc/loss:29.201300000000003% / 1.6039%, Validation acc/loss:29.883399999999998% / 1.5143%\n",
      "[3/30]: Time: 24.7s, Train acc/loss:33.5698% / 1.4997%, Validation acc/loss:37.3469% / 1.3893%\n",
      "[4/30]: Time: 24.33s, Train acc/loss:36.7423% / 1.4304000000000001%, Validation acc/loss:42.3324% / 1.3163%\n",
      "[5/30]: Time: 24.28s, Train acc/loss:40.867599999999996% / 1.3501%, Validation acc/loss:41.5452% / 1.3337999999999999%\n",
      "[6/30]: Time: 24.48s, Train acc/loss:42.377900000000004% / 1.2933%, Validation acc/loss:42.565599999999996% / 1.2991000000000001%\n",
      "[7/30]: Time: 24.41s, Train acc/loss:46.2903% / 1.2268%, Validation acc/loss:44.344% / 1.2454%\n",
      "[8/30]: Time: 24.34s, Train acc/loss:47.8613% / 1.1984%, Validation acc/loss:42.1283% / 1.3403%\n",
      "[9/30]: Time: 24.39s, Train acc/loss:49.6757% / 1.1534%, Validation acc/loss:45.8892% / 1.2833%\n",
      "[10/30]: Time: 24.45s, Train acc/loss:51.935900000000004% / 1.1147%, Validation acc/loss:52.24490000000001% / 1.0975000000000001%\n",
      "[11/30]: Time: 24.41s, Train acc/loss:52.1995% / 1.1012%, Validation acc/loss:47.9009% / 1.244%\n",
      "[12/30]: Time: 24.43s, Train acc/loss:54.8753% / 1.0467%, Validation acc/loss:54.752199999999995% / 1.0252000000000001%\n",
      "[13/30]: Time: 24.43s, Train acc/loss:55.6862% / 1.0314999999999999%, Validation acc/loss:49.5044% / 1.2251%\n",
      "[14/30]: Time: 24.36s, Train acc/loss:56.4869% / 1.0001%, Validation acc/loss:52.24490000000001% / 1.1259%\n",
      "[15/30]: Time: 24.35s, Train acc/loss:58.017399999999995% / 0.9724%, Validation acc/loss:57.8134% / 0.9726999999999999%\n",
      "[16/30]: Time: 24.42s, Train acc/loss:58.797900000000006% / 0.9412999999999999%, Validation acc/loss:48.4548% / 1.2736%\n",
      "[17/30]: Time: 24.34s, Train acc/loss:60.146% / 0.9233999999999999%, Validation acc/loss:52.7988% / 1.1017000000000001%\n",
      "[18/30]: Time: 24.35s, Train acc/loss:61.1291% / 0.8959999999999999%, Validation acc/loss:55.2187% / 1.0715000000000001%\n",
      "[19/30]: Time: 24.37s, Train acc/loss:61.453500000000005% / 0.8836999999999999%, Validation acc/loss:48.687999999999995% / 1.2381%\n",
      "[20/30]: Time: 24.33s, Train acc/loss:63.2171% / 0.8439%, Validation acc/loss:50.0875% / 1.2456%\n",
      "[21/30]: Time: 24.36s, Train acc/loss:63.7138% / 0.8352999999999999%, Validation acc/loss:44.1691% / 1.4275%\n",
      "[22/30]: Time: 24.34s, Train acc/loss:65.1429% / 0.8078%, Validation acc/loss:49.3003% / 1.2722%\n",
      "[23/30]: Time: 24.37s, Train acc/loss:65.18350000000001% / 0.7972%, Validation acc/loss:60.641400000000004% / 0.9499000000000001%\n",
      "[24/30]: Time: 24.3s, Train acc/loss:65.7308% / 0.7901999999999999%, Validation acc/loss:59.5627% / 0.9249999999999999%\n",
      "[25/30]: Time: 24.35s, Train acc/loss:66.9876% / 0.7625%, Validation acc/loss:32.5948% / 2.0052%\n",
      "[26/30]: Time: 24.35s, Train acc/loss:67.31200000000001% / 0.7591%, Validation acc/loss:57.2012% / 1.0464%\n",
      "[27/30]: Time: 24.36s, Train acc/loss:67.3829% / 0.7647%, Validation acc/loss:55.71430000000001% / 1.0854000000000001%\n",
      "[28/30]: Time: 24.35s, Train acc/loss:68.67020000000001% / 0.7121999999999999%, Validation acc/loss:59.0379% / 0.9570000000000001%\n",
      "[29/30]: Time: 24.34s, Train acc/loss:69.77499999999999% / 0.7084%, Validation acc/loss:57.93000000000001% / 1.1168%\n",
      "[30/30]: Time: 24.35s, Train acc/loss:70.08919999999999% / 0.6901%, Validation acc/loss:59.358599999999996% / 0.9843%\n"
     ]
    }
   ],
   "source": [
    "model = Classifier().cuda()   # 采用GPU模式，构建模型实例\n",
    "loss = nn.CrossEntropyLoss()  # 因为属于分类，因此定义交叉熵损失函数\n",
    "# optimizer = tc.optim.Adam(model.parameters(), lr = 0.001, betas=(0.9, 0.999))   # Use adam optimizer, lr是指learning rate\n",
    "optimizer = tc.optim.SGD(model.parameters(), lr = 0.001, momentum=0.9)\n",
    "num_epoch = 90\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    train_acc = val_acc = 0\n",
    "    train_loss = val_loss = 0\n",
    "    model.train()   # 告诉模型开始训练了，启用batch标准化和dropout\n",
    "    for i, data in enumerate(train_loader):\n",
    "        optimizer.zero_grad() # 清除原先的导数数据，进行新一轮batch的求导\n",
    "        train_pred = model(data[0].cuda())\n",
    "        batch_loss = loss(train_pred, data[1].to('cuda',dtype=tc.long)) # Loss 这里需要做类型转换\n",
    "        batch_loss.backward() # back propagation\n",
    "        optimizer.step()  # 设置一个step()\n",
    "\n",
    "        train_acc += np.sum(np.argmax(train_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
    "        # 得到的train_pred每一行是对11中类别的可能行权值，选取每一行中最大的结果的index，argmax返回的是index\n",
    "        train_loss += batch_loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    # 全称 evaluation，不启用batchNormalization和dropout，否则网络的权值会发生改变\n",
    "    # 使用PyTorch进行训练和测试时一定注意要把实例化的model指定train/eval，eval()时，\n",
    "    # 框架会自动把BatchNormalization和DropOut固定住，不会取平均，而是用训练好的值，不然的话，一旦test的batch_size过小，\n",
    "    # 很容易就会被BatchNormalization层导致生成图片颜色失真极大！！！！！！\n",
    "    with tc.no_grad():  # 停止求导\n",
    "        for i, data in enumerate(valid_loader):\n",
    "            val_pred = model(data[0].cuda())\n",
    "            batch_loss = loss(val_pred, data[1].cuda())  # 注意这里的label需要转为long类型，并且只有GPU和GPU之间的变量才能进行运算\n",
    "\n",
    "            val_acc += np.sum(np.argmax(val_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
    "            val_loss += batch_loss.item()\n",
    "\n",
    "        # 打印结果\n",
    "        print(f'[{epoch+1}/{num_epoch}]: Time: {round(time.time() - epoch_start_time,2)}s, Train acc/loss:{round(train_acc / len(train_set), 6) * 100}% / {round(train_loss / len(train_set), 6) * 100}%, Validation acc/loss:{round(val_acc / len(valid_set), 6) * 100}% / {round(val_loss / len(valid_set), 6) * 100}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6-0tlD9WlFHK"
   },
   "source": [
    "模型构建：分类器构建、损失函数构建、优化器构建\n",
    "开始训练：\n",
    "  * 循环每一个epoch\n",
    "  * 打开train模式，对每一个batch进行训练，BP，更新参数，直至所有数据训练完成\n",
    "  * 进行交叉验证，打开`eval()`模式，观察train loss和validation loss的变化。一个epoch结束，开始下一个epoch。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MlOdT3akNypE",
    "outputId": "8526a9de-aa6a-42c1-cef7-eba1b251492e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/90]: Time: 29.24716830253601, Train acc/loss:21.0% / 2.0%\n",
      "[2/90]: Time: 29.436320304870605, Train acc/loss:31.0% / 2.0%\n",
      "[3/90]: Time: 29.024319648742676, Train acc/loss:36.0% / 1.0%\n",
      "[4/90]: Time: 29.201637744903564, Train acc/loss:40.0% / 1.0%\n",
      "[5/90]: Time: 29.309746265411377, Train acc/loss:44.0% / 1.0%\n",
      "[6/90]: Time: 29.1187846660614, Train acc/loss:47.0% / 1.0%\n",
      "[7/90]: Time: 29.155373334884644, Train acc/loss:50.0% / 1.0%\n",
      "[8/90]: Time: 29.22788166999817, Train acc/loss:52.0% / 1.0%\n",
      "[9/90]: Time: 29.15738844871521, Train acc/loss:54.0% / 1.0%\n",
      "[10/90]: Time: 29.185837268829346, Train acc/loss:55.00000000000001% / 1.0%\n",
      "[11/90]: Time: 29.153873443603516, Train acc/loss:56.99999999999999% / 1.0%\n",
      "[12/90]: Time: 29.16085648536682, Train acc/loss:59.0% / 1.0%\n",
      "[13/90]: Time: 29.2264666557312, Train acc/loss:60.0% / 1.0%\n",
      "[14/90]: Time: 29.234611988067627, Train acc/loss:61.0% / 1.0%\n",
      "[15/90]: Time: 29.17455506324768, Train acc/loss:62.0% / 1.0%\n",
      "[16/90]: Time: 29.266878604888916, Train acc/loss:64.0% / 1.0%\n",
      "[17/90]: Time: 29.191754817962646, Train acc/loss:65.0% / 1.0%\n",
      "[18/90]: Time: 29.175315380096436, Train acc/loss:66.0% / 1.0%\n",
      "[19/90]: Time: 29.225884914398193, Train acc/loss:67.0% / 1.0%\n",
      "[20/90]: Time: 29.17501735687256, Train acc/loss:67.0% / 1.0%\n",
      "[21/90]: Time: 29.2230486869812, Train acc/loss:68.0% / 1.0%\n",
      "[22/90]: Time: 29.20467758178711, Train acc/loss:69.0% / 1.0%\n",
      "[23/90]: Time: 29.17641520500183, Train acc/loss:70.0% / 1.0%\n",
      "[24/90]: Time: 29.183161735534668, Train acc/loss:70.0% / 1.0%\n",
      "[25/90]: Time: 29.246544361114502, Train acc/loss:71.0% / 1.0%\n",
      "[26/90]: Time: 29.176660537719727, Train acc/loss:72.0% / 1.0%\n",
      "[27/90]: Time: 29.16283082962036, Train acc/loss:72.0% / 1.0%\n",
      "[28/90]: Time: 29.138192176818848, Train acc/loss:73.0% / 1.0%\n",
      "[29/90]: Time: 29.130728244781494, Train acc/loss:73.0% / 1.0%\n",
      "[30/90]: Time: 29.130651235580444, Train acc/loss:74.0% / 1.0%\n",
      "[31/90]: Time: 29.155534982681274, Train acc/loss:74.0% / 1.0%\n",
      "[32/90]: Time: 29.1649112701416, Train acc/loss:76.0% / 1.0%\n",
      "[33/90]: Time: 29.19729232788086, Train acc/loss:76.0% / 1.0%\n",
      "[34/90]: Time: 29.201205015182495, Train acc/loss:77.0% / 1.0%\n",
      "[35/90]: Time: 29.114292860031128, Train acc/loss:77.0% / 1.0%\n",
      "[36/90]: Time: 29.15676975250244, Train acc/loss:78.0% / 1.0%\n",
      "[37/90]: Time: 29.181545734405518, Train acc/loss:78.0% / 1.0%\n",
      "[38/90]: Time: 29.141088247299194, Train acc/loss:78.0% / 0.0%\n",
      "[39/90]: Time: 29.154370069503784, Train acc/loss:79.0% / 0.0%\n",
      "[40/90]: Time: 29.12346887588501, Train acc/loss:80.0% / 0.0%\n",
      "[41/90]: Time: 29.105680465698242, Train acc/loss:80.0% / 0.0%\n",
      "[42/90]: Time: 29.15513515472412, Train acc/loss:81.0% / 0.0%\n",
      "[43/90]: Time: 29.119116067886353, Train acc/loss:82.0% / 0.0%\n",
      "[44/90]: Time: 29.169259786605835, Train acc/loss:81.0% / 0.0%\n",
      "[45/90]: Time: 29.16761541366577, Train acc/loss:82.0% / 0.0%\n",
      "[46/90]: Time: 29.166110277175903, Train acc/loss:83.0% / 0.0%\n",
      "[47/90]: Time: 29.20757484436035, Train acc/loss:83.0% / 0.0%\n",
      "[48/90]: Time: 29.110511779785156, Train acc/loss:83.0% / 0.0%\n",
      "[49/90]: Time: 29.144824504852295, Train acc/loss:84.0% / 0.0%\n",
      "[50/90]: Time: 29.14455223083496, Train acc/loss:85.0% / 0.0%\n",
      "[51/90]: Time: 29.135324478149414, Train acc/loss:85.0% / 0.0%\n",
      "[52/90]: Time: 29.144611358642578, Train acc/loss:85.0% / 0.0%\n",
      "[53/90]: Time: 29.105064868927002, Train acc/loss:85.0% / 0.0%\n",
      "[54/90]: Time: 29.157281160354614, Train acc/loss:86.0% / 0.0%\n",
      "[55/90]: Time: 29.238808393478394, Train acc/loss:87.0% / 0.0%\n",
      "[56/90]: Time: 29.29281783103943, Train acc/loss:88.0% / 0.0%\n",
      "[57/90]: Time: 29.279054641723633, Train acc/loss:88.0% / 0.0%\n",
      "[58/90]: Time: 29.17389440536499, Train acc/loss:88.0% / 0.0%\n",
      "[59/90]: Time: 29.18483853340149, Train acc/loss:89.0% / 0.0%\n",
      "[60/90]: Time: 29.2194344997406, Train acc/loss:89.0% / 0.0%\n",
      "[61/90]: Time: 29.191813468933105, Train acc/loss:89.0% / 0.0%\n",
      "[62/90]: Time: 29.171322345733643, Train acc/loss:90.0% / 0.0%\n",
      "[63/90]: Time: 29.23443055152893, Train acc/loss:90.0% / 0.0%\n",
      "[64/90]: Time: 29.18168044090271, Train acc/loss:90.0% / 0.0%\n",
      "[65/90]: Time: 29.226321935653687, Train acc/loss:90.0% / 0.0%\n",
      "[66/90]: Time: 29.18507719039917, Train acc/loss:91.0% / 0.0%\n",
      "[67/90]: Time: 29.196858882904053, Train acc/loss:91.0% / 0.0%\n",
      "[68/90]: Time: 29.195822715759277, Train acc/loss:91.0% / 0.0%\n",
      "[69/90]: Time: 29.19571852684021, Train acc/loss:91.0% / 0.0%\n",
      "[70/90]: Time: 29.167607307434082, Train acc/loss:92.0% / 0.0%\n",
      "[71/90]: Time: 29.181681394577026, Train acc/loss:92.0% / 0.0%\n",
      "[72/90]: Time: 29.180582523345947, Train acc/loss:92.0% / 0.0%\n",
      "[73/90]: Time: 29.174710035324097, Train acc/loss:93.0% / 0.0%\n",
      "[74/90]: Time: 29.20784568786621, Train acc/loss:93.0% / 0.0%\n",
      "[75/90]: Time: 29.18568992614746, Train acc/loss:93.0% / 0.0%\n",
      "[76/90]: Time: 29.189629554748535, Train acc/loss:94.0% / 0.0%\n",
      "[77/90]: Time: 29.21193218231201, Train acc/loss:94.0% / 0.0%\n",
      "[78/90]: Time: 29.21555471420288, Train acc/loss:94.0% / 0.0%\n",
      "[79/90]: Time: 29.164226770401, Train acc/loss:94.0% / 0.0%\n",
      "[80/90]: Time: 29.21156096458435, Train acc/loss:94.0% / 0.0%\n",
      "[81/90]: Time: 29.15206503868103, Train acc/loss:94.0% / 0.0%\n",
      "[82/90]: Time: 29.18774700164795, Train acc/loss:95.0% / 0.0%\n",
      "[83/90]: Time: 29.267189741134644, Train acc/loss:95.0% / 0.0%\n",
      "[84/90]: Time: 29.11671257019043, Train acc/loss:95.0% / 0.0%\n",
      "[85/90]: Time: 29.18697953224182, Train acc/loss:95.0% / 0.0%\n",
      "[86/90]: Time: 29.079960346221924, Train acc/loss:95.0% / 0.0%\n",
      "[87/90]: Time: 29.19012451171875, Train acc/loss:96.0% / 0.0%\n",
      "[88/90]: Time: 29.178375959396362, Train acc/loss:96.0% / 0.0%\n",
      "[89/90]: Time: 29.217617988586426, Train acc/loss:95.0% / 0.0%\n",
      "[90/90]: Time: 29.153480052947998, Train acc/loss:95.0% / 0.0%\n"
     ]
    }
   ],
   "source": [
    "# 使用最好的参数\n",
    "train_val_x = np.concatenate((train_x, valid_x), axis=0)\n",
    "train_val_y = np.concatenate((train_y, valid_y), axis=0)\n",
    "train_val_set = ImgDataset(train_val_x, train_val_y, train_transform)\n",
    "train_val_dataloader = dataloader.DataLoader(train_val_set, batch_size, True)\n",
    "\n",
    "model_best = Classifier().cuda()\n",
    "loss = nn.CrossEntropyLoss()\n",
    "# optimizer = tc.optim.Adam(model_best.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "optimizer = tc.optim.SGD(model_best.parameters(), lr = 0.001, momentum=0.9)\n",
    "num_epoch = 90\n",
    "for epoch in range(num_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    train_acc, train_loss = 0, 0\n",
    "\n",
    "    model_best.train()\n",
    "    for i, data in enumerate(train_val_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        train_pred = model_best(data[0].cuda())\n",
    "        batch_loss = loss(train_pred, data[1].cuda())\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_acc += np.sum(np.argmax(train_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
    "        train_loss += batch_loss.item()\n",
    "    print(f'[{epoch+1}/{num_epoch}]: Time: {time.time() - epoch_start_time}, Train acc/loss:{round(train_acc / len(train_val_set), 2) * 100}% / {round(train_loss / len(train_val_set), 2) * 100}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "pHxSu1wziKtg"
   },
   "outputs": [],
   "source": [
    "tc.save(model_best,\"model_best.torch\")  # 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R0OGkuvDNyx-",
    "outputId": "8d9e97d0-cbfe-45f5-fa6a-cd971c888001"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost time: 7360.32 s\n"
     ]
    }
   ],
   "source": [
    "test_x = read_file(os.path.join(dir_path, 'testing'), False)\n",
    "test_set = ImgDataset(test_x, transform=test_transform)\n",
    "test_loader = dataloader.DataLoader(test_set, batch_size, False)\n",
    "model_best.eval()\n",
    "\n",
    "predication = []\n",
    "with tc.no_grad():\n",
    "    for i, data in enumerate(test_loader):\n",
    "        test_pred = model_best(data.cuda())\n",
    "        test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n",
    "        for y in test_label:\n",
    "            predication.append(y)\n",
    "\n",
    "rs = pd.DataFrame(predication,columns=['label'])\n",
    "rs.to_csv('ans.csv')\n",
    "\n",
    "print(f'Cost time: {round(time.time() - s_time, 2)} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LsZfbefkJ34Y"
   },
   "source": [
    "## 结论与展望\n",
    "* 第一次照猫画虎，搞清了pytorch的基本使用以及基本流程，得分为0.60251(**<font color='red'>未达标</font>**)\n",
    "\n",
    "  **分析原因：**\n",
    "    * 没有设置momentum以及dropout\n",
    "    * 完整训练的时候数据集使用的是完整测试前train的数据集 :(\n",
    "* 第二次优化器改用`SGD+momentum`,添加了dropout，获得了0.79378（差一点达到strong \n",
    "baseline）\n",
    "\n",
    "* 说实话感觉还是没有调超参的话，用不着使用validation（evaluation），否则感觉实在浪费时间。两个90个epoch，每个epoch耗费30s，一个小时就这么过去了。\n",
    "* 看一些大佬的代码，感觉之间的差距实在做CNN的那部分以及神经网络那部分有不同：\n",
    "  * 除了对于通道 3 -> 64 之间转换之外，其还对自己本身64 -> 64也做了卷积和归一化。并且每一步都做，转到另一个数目的通道时候才池化。\n",
    "  * 其使用的网络层数比我多一层。\n",
    "\n",
    "* **这个只是基本了解了pytorch与CNN的流程，后续还需要继续对这一部分进行自我手刻不参考其他人的代码。**\n",
    "\n",
    "参考文章：\n",
    "\n",
    "* 理解卷积神经网络中的通道 https://blog.csdn.net/sscc_learning/article/details/79814146 \n",
    "* torch.nn.Conv2d()的理解 https://blog.csdn.net/qq_38863413/article/details/104108808\n",
    "* Pytorch中的DataLoader和Dataset https://pytorch.org/docs/stable/data.html\n",
    "* Pytorch中model.train()与model.eval()的作用 https://blog.csdn.net/qq_38410428/article/details/101102075\n",
    "* 各种算法收敛比较 https://blog.csdn.net/u010089444/article/details/76725843\n",
    "* Adam具体介绍以及建议参数 https://blog.csdn.net/leadai/article/details/79178787"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hw3_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
